# Variational Autoencoder with 2D Latent Space ğŸ§ âœ¨

An interactive PyTorch implementation of a Variational Autoencoder (VAE) trained on MNIST digits with a 2-dimensional latent space. Explore the learned representations through an interactive web interface with real-time digit generation and latent space visualization.

[![Watch the video](images/youtube_window_1.png)](https://www.youtube.com/embed/IR9TJbwHhXM?si=bgyeu6FJk8w35i0v)

## ğŸ“‹ Description

This project implements a Variational Autoencoder with a constrained 2-dimensional latent space, making the learned representations easily visualizable and interpretable. By training on the MNIST dataset, the model learns to generate handwritten digits while maintaining a meaningful latent space that can be explored interactively.

The interactive Streamlit application allows users to navigate the 2D latent space using sliders, observe individual digit generation, and visualize a grid of generated digits centered at any point in the latent space.

<br>
<div align="center">
  <a href="https://variational-autoencoder-2d-latent-mnist.streamlit.app/">
    <img src="https://img.shields.io/badge/Try-Interactive_Simulator-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit App" style="height: 50px;"/>
  </a>
</div>
<br>
<div align="center">
  <a href="https://codeload.github.com/TendoPain18/variational-autoencoder-2d-latent-mnist/legacy.zip/main">
    <img src="https://img.shields.io/badge/Download-Files-brightgreen?style=for-the-badge&logo=download&logoColor=white" alt="Download Demo" style="height: 50px;"/>
  </a>
</div>

## ğŸ¯ Project Objectives

1. **Build a VAE Architecture**: Implement encoder and decoder networks
2. **2D Latent Space**: Constrain latent representation to 2 dimensions for visualization
3. **MNIST Training**: Train on handwritten digit dataset
4. **Interactive Exploration**: Create web interface for latent space navigation
5. **Digit Generation**: Real-time generation at arbitrary latent coordinates

## âœ¨ Features

### VAE Architecture
- **Encoder Network**: 784 â†’ 400 â†’ 200 â†’ 2 (mean and log-variance)
- **Latent Space**: 2-dimensional with reparameterization trick
- **Decoder Network**: 2 â†’ 200 â†’ 400 â†’ 784 (sigmoid output)
- **Loss Function**: Binary cross-entropy + KL divergence

### Interactive Interface
- **Dual Slider Controls**: Adjust Zâ‚ and Zâ‚‚ independently (-3 to +3 range)
- **Single Digit Generation**: Real-time digit synthesis at current latent position
- **Latent Space Grid**: 10Ã—10 grid of generated digits centered on current point
- **Dynamic Grid**: Grid shifts as sliders move for continuous exploration

### Visualization
- **Control Panel**: Left column with Zâ‚ and Zâ‚‚ sliders
- **Generated Digit**: Center column with individual digit display
- **Latent Space Grid**: Right column with 10Ã—10 exploration grid
- **Responsive Layout**: Wide layout for optimal display

## ğŸ”¬ Theoretical Background

### Variational Autoencoder (VAE)

**Architecture:**

The VAE consists of two main components:

1. **Encoder (Inference Network):**
```
q(z|x) = N(Î¼(x), ÏƒÂ²(x))
```
Maps input x to latent distribution parameters

2. **Decoder (Generative Network):**
```
p(x|z) = Bernoulli(decoder(z))
```
Reconstructs input from latent sample

**Reparameterization Trick:**
```
z = Î¼ + Ïƒ âŠ™ Îµ    where Îµ ~ N(0, 1)
```

Allows gradient flow through stochastic sampling.

### Loss Function

**ELBO (Evidence Lower Bound):**
```
L = E_q[log p(x|z)] - D_KL(q(z|x) || p(z))
  = Reconstruction Loss + KL Divergence
```

**Components:**

1. **Reconstruction Loss** (Binary Cross-Entropy):
```
BCE = -Î£ [xÂ·log(xÌ‚) + (1-x)Â·log(1-xÌ‚)]
```

2. **KL Divergence** (Regularization):
```
D_KL = 0.5 Î£ [1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²]
```

### 2D Latent Space Interpretation

**Meaningful Representation:**
- Points in latent space correspond to different digit styles and orientations
- Interpolation between points smoothly transitions between digit variations
- Gaussian prior ensures efficient use of latent space

**Example Latent Traversal:**
```
Zâ‚ axis: Digit rotation/thickness variations
Zâ‚‚ axis: Digit type variations (similar digits)
Diagonal: Combined variations
```

## ğŸ“Š Model Architecture

### Encoder Architecture
```
Input (28Ã—28 = 784)
    â†“
Linear(784 â†’ 400) + LeakyReLU(0.5)
    â†“
Linear(400 â†’ 200) + LeakyReLU(0.2)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             â”‚
Linear(200 â†’ 2)      Linear(200 â†’ 2)
â†“                            â†“
Î¼ (mean)            log ÏƒÂ² (log-variance)
```

### Decoder Architecture
```
Latent Code (2)
    â†“
Linear(2 â†’ 200) + LeakyReLU(0.2)
    â†“
Linear(200 â†’ 400) + LeakyReLU(0.5)
    â†“
Linear(400 â†’ 784) + Sigmoid
    â†“
Output (28Ã—28 = 784)
```

### Hyperparameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| Input Dim | 784 | 28Ã—28 MNIST images flattened |
| Hidden Dim | 400 | First hidden layer size |
| Latent Dim | 2 | 2D latent space |
| Batch Size | 32 | Training batch size |
| Learning Rate | 1e-4 | Adam optimizer LR |
| Epochs | 100 | Training epochs |
| Beta (KL weight) | 1.0 | KL divergence weight |

## ğŸ–¥ï¸ Interactive Interface

<img src="images/main_interface.png" alt="Main Interface" width="700"/>

*Interactive Streamlit interface showing all three visualization panels*

### Interface Components

**Left Panel - Controls:**
- Zâ‚ Slider: Range -3.0 to +3.0, step 0.05
- Zâ‚‚ Slider: Range -3.0 to +3.0, step 0.05
- Current Latent Vector Display
- Real-time updates

**Center Panel - Generated Digit:**
- 28Ã—28 pixel display
- Current latent position indicator
- High-quality MNIST-style output

**Right Panel - Latent Space Grid:**
- 10Ã—10 grid of generated digits
- Centered on current (Zâ‚, Zâ‚‚) position
- Grid updates dynamically as sliders move
- Spacing: 1.5 units in both directions
- Shows local latent space structure

### Grid Generation Algorithm
```
grid_size = 10
span = 1.5

z1_grid = Zâ‚ + linspace(-span, span, grid_size)
z2_grid = Zâ‚‚ + linspace(span, -span, grid_size)

for i in range(grid_size):
    for j in range(grid_size):
        digit = model.decode([z1_grid[i], z2_grid[j]])
        display_at(column[i], row[j])
```

## ğŸ¨ Generated Samples

### Single Digit Generation

<img src="images/generated_digit.png" alt="Generated Digit" width="400"/>

*Example generated digit from random latent vector*

### Latent Space Exploration

<img src="images/latent_space_grid.png" alt="Latent Space Grid" width="700"/>

*10Ã—10 grid showing local latent space structure*

**Observations:**
- Neighboring digits are visually similar
- Smooth transitions across grid
- Clear digit variations along principal directions
- Well-organized latent space

### Control Bars

<img src="images/control_bars.png" alt="Control Bars" width="400"/>

*Interactive slider controls for latent space navigation*

## ğŸš€ Getting Started

### Prerequisites

**Python Requirements:**
```
torch 2.0+
torchvision 0.15+
streamlit 1.28+
matplotlib 3.7+
numpy 1.24+
PIL 9.0+
```

**System Requirements:**
- CUDA 11.8+ (optional, for GPU acceleration)
- 4GB RAM minimum
- Modern web browser for Streamlit app

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/variational-autoencoder-2d-latent-space.git
cd variational-autoencoder-2d-latent-space
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Download/Train Model**
```bash
# Option 1: Use pre-trained model
# (Download from releases)

# Option 2: Train from scratch
python train.py
```

4. **Run Streamlit App**
```bash
streamlit run app.py
```

The app will open at `http://localhost:8501`

## ğŸ“– Usage Guide

### Training a Model

**From scratch:**
```bash
python train.py
```

Configuration options in `train.py`:
- Batch size: 32 (line 10)
- Learning rate: 1e-4 (line 11)
- Epochs: 100 (line 12)
- Latent dimension: 2 (line 18)

**Custom MNIST path:**
```python
train_loader, _ = get_mnist_loaders(
    batch_size=32,
    data_path='./data'  # Custom path
)
```

### Running the Interactive App

**Using Pre-trained Model:**
```bash
# Model must be in: trained_model/vae_mnist.pth
streamlit run app.py
```

**Using Custom Model:**
```python
# Edit app.py line 12-14
MODEL_PATH = "your_model_path/vae_mnist.pth"
model = VAE(latent_dim=2).to(DEVICE)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
```

### Exploring the Latent Space

1. **Navigate using sliders:**
   - Move Zâ‚ slider to explore horizontal variations
   - Move Zâ‚‚ slider to explore vertical variations
   - Observe digit generation updates in real-time

2. **Watch the grid shift:**
   - Grid stays centered on current point
   - Neighboring digits show smooth transitions
   - Extremes show digit diversity

3. **Identify patterns:**
   - Similar digits cluster together
   - Rotation/thickness variations along axes
   - Interpolation between digit types

## ğŸ”§ Technical Details

### Key Components

**VAE Class** (`my_models/vae.py`):
- Encoder: Maps MNIST image to latent parameters
- Reparameterize: Implements sampling trick
- Decode: Generates image from latent vector
- Forward: Complete forward pass

**Loss Function** (`utils/loss.py`):
```python
def vae_loss(recon_x, x, mu, logvar):
    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD
```

**Streamlit App** (`app.py`):
- Model loading and caching
- Interactive slider controls
- Real-time grid generation
- Responsive visualization

## ğŸ“ Learning Outcomes

This project demonstrates:

1. **Generative Models**: Understanding VAE architecture and training
2. **Latent Representations**: Learning meaningful low-dimensional embeddings
3. **Probability Theory**: Reparameterization trick, KL divergence
4. **PyTorch**: Neural network implementation and training
5. **Web Interfaces**: Building interactive apps with Streamlit
6. **Visualization**: Effective display of high-dimensional data
7. **2D Visualization**: Exploring latent spaces in 2D

## ğŸ”„ Future Improvements

- Extend to higher-dimensional latent spaces
- Implement Î²-VAE for interpretability
- Add semi-supervised learning
- Support for other datasets (CIFAR-10, CelebA)
- Adversarial VAE (AAE) variant
- Attention mechanisms in decoder
- Multi-scale architecture

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

- Suggest architectural improvements
- Add new features to Streamlit app
- Improve training efficiency
- Add more visualization options
- Optimize model performance

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- MNIST dataset from Yann LeCun
- PyTorch framework and community
- Streamlit for web app framework
- VAE foundational papers (Kingma & Welling, 2013)

<br>
<div align="center">
  <a href="https://codeload.github.com/TendoPain18/variational-autoencoder-2d-latent-mnist/legacy.zip/main">
    <img src="https://img.shields.io/badge/Download-Files-brightgreen?style=for-the-badge&logo=download&logoColor=white" alt="Download Demo" style="height: 50px;"/>
  </a>
</div>

## **Explore the beautiful world of generative models! ğŸ§ âœ¨**
